{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lightning Tour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduces the main ways of using Saber.\n",
    "\n",
    "### Table of contents\n",
    "\n",
    "1. [Quick Start](#Quick-Start)\n",
    "    1. [Web-service](#Web-service)\n",
    "    2. [Pre-trained models](#Pre-trained-models)\n",
    "        1. [Working with annotations](#Working-with-annotations)\n",
    "        \n",
    "2. [Guide to the Saber API](#Guide-to-the-Saber-API)  \n",
    "    1. [Command line tool](#Command-line-tool)\n",
    "    2. [Python package](#Python-package)\n",
    "        1. [Transfer learning](#Transfer-learning)\n",
    "        2. [Multi-task learning](#Multi-task-learning)\n",
    "        3. [Saving and loading models](#Saving-and-loading-models)\n",
    "            1. [Saving a model](#Saving-a-model)\n",
    "            2. [Loading a model](#Loading-a-model)\n",
    "4. [Visualizations](#Visualizations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Start\n",
    "\n",
    "If your goal is simply to use Saber to annotate biomedical text, then you can either use the [web-service](#Web-service) or a [pre-trained model](#pre-trained-models)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web-service\n",
    "\n",
    "To use Saber as a **local** web-service, run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python -m saber.app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or, if you prefer, you can pull & run the Saber image from **Docker Hub**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull Saber image from Docker Hub\n",
    "! docker pull pathwaycommons/saber\n",
    "# Run docker (use `-dt` instead of `-it` to run container in background)\n",
    "! docker run -it --rm -p 5000:5000 --name saber pathwaycommons/saber"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Alternatively, you can clone the GitHub repository and build the container from the `Dockerfile` with `docker build -t saber .`\n",
    "\n",
    "The web-service is now live, and can be accessed by directing your browser here: [http://127.0.0.1:5000/](http://127.0.0.1:5000/). Although you can run these commands in the notebook, it makes more sense to copy paste them directly into the shell. Just remember to remove the proceeding \"!\".\n",
    "\n",
    "\n",
    "There are currently two endpoints, /annotate/text and /annotate/pmid. Both expect a POST request with a JSON payload, e.g."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```json\n",
    "{\n",
    "  \"text\": \"The phosphorylation of Hdm2 by MK2 promotes the ubiquitination of p53.\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```json\n",
    "{\n",
    "  \"pmid\": 11835401\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, with the web-service running locally and using `cURL`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curl -X POST 'http://localhost:5000/annotate/text' --data '{\"text\": \"The phosphorylation of Hdm2 by MK2 promotes the ubiquitination of p53.\"}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentation for the Saber web-service API can be found [here](https://baderlab.github.io/saber-api-docs/). We hope to provide a live version of the web-service soon!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-trained models\n",
    "\n",
    "First, import `SequenceProcessor`. This class coordinates training, annotation, saving and loading of models and datasets. In short, this is the interface to Saber."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from saber.sequence_processor import SequenceProcessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load a pre-trained model, we first create a `SequenceProcessor` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = SequenceProcessor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and then load the model of our choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.load('PRGE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see all the pre-trained models in the [web-service API docs](https://baderlab.github.io/saber-api-docs/) or, alternatively, by running the following line of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from saber.constants import ENTITIES; print(list(ENTITIES.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To annotate text with the model, just call the `annotate()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"The phosphorylation of Hdm2 by MK2 promotes the ubiquitination of p53.\"\n",
    "# text = \"Interleukin-6 is a multifaceted cytokine, usually reported as a pro-inflammatory molecule. However, certain anti-inflammatory activities were also attributed to IL-6. The levels of IL-6 in serum as well as in other biological fluids are elevated in an age-dependent manner. Notably, it is consistently reported also as a key feature of the senescence-associated secretory phenotype. In the elderly, this cytokine participates in the initiation of catabolism resulting in, e.g. sarcopenia. It can cross the blood-brain barrier, and so it is in causal association with, e.g. depression, bipolar disorder, schizophrenia, and anorexia. In the cancer patient, IL-6 is produced by cancer and stromal cells and actively participates in their crosstalk. IL-6 supports tumour growth and metastasising in terminal patients, and it significantly engages in cancer cachexia (including anorexia) and depression associated with malignancy. The pharmacological treatment impairing IL-6 signalling represents a potential mechanism of anti-tumour therapy targeting cancer growth, metastatic spread, metabolic deterioration and terminal cachexia in patients.\"\n",
    "sp.annotate(text, coref=False, jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coreference Resolution\n",
    "\n",
    "[**Coreference**](http://www.wikiwand.com/en/Coreference) occurs when two or more expressions in a text refer to the same person or thing, that is, they have the same **referent**. Take the following example:\n",
    "\n",
    "_\"IL-6 supports tumour growth and metastasising in terminal patients, and it significantly engages in cancer cachexia (including anorexia) and depression associated with malignancy.\"_\n",
    "\n",
    "Clearly, _\"it\"_ referes to _\"IL-6\"_. If we do not resolve this coreference, then _\"it\"_ will not be labeled as an entity and any relation or event it is mentioned in will not be extracted. Saber uses [NeuralCoref](https://github.com/huggingface/neuralcoref), a state-of-the-art coreference resolution tool based on neural nets and built on top of [Spacy](https://spacy.io). To use it, just supply the argument `coref=True` (which is `False` by default) to the `annotate()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"IL-6 supports tumour growth and metastasising in terminal patients, and it significantly engages in cancer cachexia (including anorexia) and depression associated with malignancy.\"\n",
    "# WITHOUT coreference resolution\n",
    "sp.annotate(text, coref=False, jupyter=True)\n",
    "# WITH coreference resolution\n",
    "sp.annotate(text, coref=True, jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note that if you are using the web-service, simply supply `\"coref\": true` in your `JSON` payload to resolve coreferences.\n",
    "\n",
    "Saber currently takes the simplest possible approach: replace all coreference mentions with their referent, and then feed the resolved text to the model that identifies named entities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Working with annotations\n",
    "\n",
    "The `annotate()` method returns a simple `dict` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = sp.annotate(\"The phosphorylation of Hdm2 by MK2 promotes the ubiquitination of p53.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which contains the keys `title`, `text` and `ents`:\n",
    "\n",
    "- `title`: contains the title of the article, if provided\n",
    "- `text`: contains the text (which is minimally processed) the model was deployed on\n",
    "- `ents`: contains a list of entities present in the `text` that were annotated by the model\n",
    "\n",
    "For example, to see all entities annotated by the model, call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann['ents']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Converting annotations to JSON\n",
    "\n",
    "The `annotate()` method returns a `dict` object, but can be converted to a `JSON` formatted string for ease-of-use in downstream applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# convert to json object\n",
    "json_ann = json.dumps(ann)\n",
    "\n",
    "# convert back to python dictionary\n",
    "ann = json.loads(json_ann)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guide to the Saber API\n",
    "\n",
    "You can interact with Saber as a web-service (explained in [Quick Start](#Quick-Start), command line tool, python package, or via the Juypter notebooks. If you created a virtual environment, _remember to activate it first_.\n",
    "\n",
    "Note: To train you own models, you will need to proved a dataset (or datasets!) and, ideally, pre-trained word embeddings. See [Resources](https://baderlab.github.io/saber/resources/) for help preparing datasets for training.\n",
    "\n",
    "### Command line tool\n",
    "\n",
    "Currently, the command line tool simply trains the model. To use it, call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python -m saber.train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Again, while you can run these commands in the notebook, it makes more sense to copy paste them directly into the shell. Just remember to remove the proceeding \"!\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "along with any command line arguments. For example, to train the model on the [NCBI Disease](https://www.ncbi.nlm.nih.gov/CBBresearch/Dogan/DISEASE/) corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python -m saber.train --dataset_folder NCBI_disease_BIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run `python -m saber.train -h` to see all possible arguments.\n",
    "\n",
    "Of course, supplying arguments at the command line can quickly become cumbersome. Saber also allows you to specify a configuration file, which can be specified like so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python -m saber.train --config_filepath path/to/config.ini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy the contents of the [default config file](https://github.com/BaderLab/saber/blob/master/saber/config.ini) to a new `*.ini` file in order to get started.\n",
    "\n",
    "Note that arguments supplied at the command line overwrite those found in the configuration file. For example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python -m saber.train --dataset_folder path/to/dataset --k_folds 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "would overwrite the arguments for `dataset_folder` and `k_folds` found in the configuration file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python package\n",
    "\n",
    "You can also import Saber and interact with it as a python package. Saber exposes its functionality through the `SequenceProcessor` class. Here is just about everything Saber does in one script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from saber.sequence_processor import SequenceProcessor\n",
    "\n",
    "# First, create a SequenceProcessor object, which exposes Sabers functionality\n",
    "sp = SequenceProcessor()\n",
    "\n",
    "# Load a dataset and create a model (provide a list of datasets to use multi-task learning!)\n",
    "sp.load_dataset('path/to/datasets/GENIA')\n",
    "sp.create_model()\n",
    "\n",
    "# Train and save a model\n",
    "sp.fit()\n",
    "sp.save('pretrained_models/GENIA')\n",
    "\n",
    "# Load a model\n",
    "del sp\n",
    "sp = SequenceProcessor()\n",
    "sp.load('pretrained_models/GENIA')\n",
    "\n",
    "# Perform prediction on raw text, get resulting annotation\n",
    "raw_text = 'The phosphorylation of Hdm2 by MK2 promotes the ubiquitination of p53.'\n",
    "annotation = sp.annotate(raw_text)\n",
    "\n",
    "# Use transfer learning to continue training on a new dataset\n",
    "sp.load_dataset('path/to/datasets/CRAFT')\n",
    "sp.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transfer learning\n",
    "\n",
    "Transfer learning is as easy as training, saving, loading, and then continuing training of a model. Here is an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train a model on GENIA corpus\n",
    "sp = SequenceProcessor()\n",
    "sp.load_dataset('path/to/datasets/GENIA')\n",
    "sp.create_model()\n",
    "sp.fit()\n",
    "sp.save('pretrained_models/GENIA')\n",
    "\n",
    "# Load that model\n",
    "del sp\n",
    "sp = SequenceProcessor()\n",
    "sp.load('pretrained_models/GENIA')\n",
    "\n",
    "# Use transfer learning to continue training on a new dataset\n",
    "sp.load_dataset('path/to/datasets/CRAFT')\n",
    "sp.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note that there is currently no way to easily do this with the command line interface, but I am working on it!\n",
    "\n",
    "#### Multi-task learning\n",
    "\n",
    "Multi-task learning is as easy as specifying multiple dataset paths, either in the `config` file, at the command line via the flag `--dataset_folder`, or as an argument to `load_dataset()`. The number of datasets is arbitrary.\n",
    "\n",
    "Here is an example using the last method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = SequenceProcessor()\n",
    "\n",
    "# Simply pass multiple dataset paths as a list to load_dataset to use multi-task learning.\n",
    "sp.load_dataset(['path/to/datasets/NCBI-Disease', 'path/to/datasets/Linnaeus'])\n",
    "\n",
    "sp.create_model()\n",
    "sp.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving and loading models\n",
    "\n",
    "In the following sections we introduce the saving and loading of models.\n",
    "\n",
    "##### Saving a model\n",
    "\n",
    "Assuming the model has already been created (see above), we can easily save our model like so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_saved_model = 'path/to/pretrained_models/mymodel'\n",
    "\n",
    "sp.save(path_to_saved_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading a model\n",
    "\n",
    "Lets illustrate loading a model with a new `SequenceProccesor` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete our previous SequenceProccesor object (if it exists)\n",
    "if 'sp' in locals(): del sp\n",
    "\n",
    "# Create a new SequenceProccesor object\n",
    "sp = SequenceProcessor()\n",
    "\n",
    "# Load a previous model\n",
    "sp.load(path_to_saved_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations\n",
    "\n",
    "_Note: This is less a feature and more a by-product of the fact that the model is implemented in [Keras](https://keras.io)._\n",
    "\n",
    "We can easily create an image depiction our model. First, install the [graphviz graph library](http://www.graphviz.org/) and the [Python interface](https://pypi.python.org/pypi/graphviz). This is useful if you plan on modifying the architecture of the model.\n",
    "\n",
    "> More info can be found [here](https://machinelearningmastery.com/visualize-deep-learning-neural-network-model-keras/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming sp is a `SequenceProcessor` object and `sp.create_model()` has been called\n",
    "sp = SequenceProcessor()\n",
    "\n",
    "# set this variable equal to your Keras model object.\n",
    "model_ = sp.model.model[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can either: create and save an image on our local machine,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model_, to_file='model.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or, visualize it directly in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model_, show_shapes=True, show_layer_names=True).create(prog='dot', format='svg'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:saber]",
   "language": "python",
   "name": "conda-env-saber-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
