{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kari"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduces the main ways of using Kari."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the neccecary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kari version: 0.1-dev\n"
     ]
    }
   ],
   "source": [
    "from dataset import Dataset\n",
    "from utils_parameter_parsing import *\n",
    "from sequence_processing_model import SequenceProcessingModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the parameters from the config file and create a model. Note that you can also overide any arguments in `config.ini` by passing them in a dictionary to `process_parameters`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = config_parser('./config.ini') # parse config.ini\n",
    "parameters = process_parameters(config, {}) # process_parameters expects a dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `SequenceProcessingModel` object. This object coordinates training/prediction/loading of models and datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_processer = SequenceProcessingModel(**parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then load the dataset (specified by the `dataset_text_folder` parameter). If pretrained token embeddings were specified with `token_pretrained_embedding_filepath`, these will be loaded also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_processer.load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we specify the model we would like to use. Models are specified by the `model_name` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_processer.specify_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_processer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero((pred_idx == gold_idx)) / len(pred_idx)\n",
    "# gold_idx[:18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_processing_model.ds.tag_type_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_tag = sequence_processing_model.ds.tag_type_to_index['O']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_labels = gold_idx != neg_tag\n",
    "gold_labels[:18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels = pred_idx != neg_tag\n",
    "pred_labels[:18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = 0\n",
    "FP = 0\n",
    "FN = 0\n",
    "\n",
    "for pred, gold in zip(pred_labels, gold_labels):\n",
    "    # FN\n",
    "    if gold and not pred:\n",
    "        FN += 1\n",
    "    # FP\n",
    "    if not gold and pred:\n",
    "        FP += 1\n",
    "    # TP\n",
    "    if gold and pred:\n",
    "        TP += 1\n",
    "        \n",
    "precision = TP / (TP + FP)\n",
    "recall = TP / (TP + FN)\n",
    "f1 = 2 * precision * recall / (precision + recall)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP, FP, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kari version: 0.1-dev\n"
     ]
    }
   ],
   "source": [
    "from utils_parameter_parsing import *\n",
    "from sequence_processing_model import SequenceProcessingModel\n",
    "\n",
    "config = config_parser('./config.ini') # parse config.ini\n",
    "parameters = process_parameters(config, {'model_name': 'MT-LSTM-CRF'}) # process_parameters expects a dictionary\n",
    "\n",
    "sequence_processer = SequenceProcessingModel(**parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading (compound) dataset... Done (2.61 seconds)\n",
      "Loading embeddings... Done (105.85 seconds)\n",
      "Found 1891782 word vectors of dimension 200\n"
     ]
    }
   ],
   "source": [
    "sequence_processer.load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the multi-task LSTM-CRF model...WARNING:tensorflow:From /Users/johngiorgi/miniconda3/envs/kari/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1247: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /Users/johngiorgi/miniconda3/envs/kari/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1230: calling reduce_min (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /Users/johngiorgi/miniconda3/envs/kari/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1364: calling reduce_any (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /Users/johngiorgi/miniconda3/envs/kari/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1489: calling reduce_logsumexp (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /Users/johngiorgi/miniconda3/envs/kari/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1349: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 50, 200)           5650600   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 50, 200)           240800    \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 50, 100)           20100     \n",
      "_________________________________________________________________\n",
      "crf_1 (CRF)                  (None, 50, 5)             540       \n",
      "=================================================================\n",
      "Total params: 5,912,040\n",
      "Trainable params: 261,440\n",
      "Non-trainable params: 5,650,600\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 50, 200)           5650600   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 50, 200)           240800    \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 50, 100)           20100     \n",
      "_________________________________________________________________\n",
      "crf_2 (CRF)                  (None, 50, 5)             540       \n",
      "=================================================================\n",
      "Total params: 5,912,040\n",
      "Trainable params: 261,440\n",
      "Non-trainable params: 5,650,600\n",
      "_________________________________________________________________\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "sequence_processer.specify_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'kf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-7b3bf535b6f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msequence_processer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/Masters/Class/natural_language_computing/project/multi-task-learning-BNER-trigger-word/kari/sequence_processing_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mcheckpointer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_model_checkpointing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;31m# fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0mtrain_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpointer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpointer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m         '''\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Masters/Class/natural_language_computing/project/multi-task-learning-BNER-trigger-word/kari/models/multi_task_lstm_crf.py\u001b[0m in \u001b[0;36mfit_\u001b[0;34m(self, checkpointer)\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_word_idx_sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_tag_idx_sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mtrain_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_word_idx_sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m                 data_splits.append({'X_train':X[train_idx],\n\u001b[1;32m    150\u001b[0m                                     \u001b[0;34m'X_valid'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalid_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'kf' is not defined"
     ]
    }
   ],
   "source": [
    "sequence_processer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visulize the model\n",
    "\n",
    "We can easily create an image depicted our model. First, install the [graphviz graph library](http://www.graphviz.org/) and the [Python interface](https://pypi.python.org/pypi/graphviz).\n",
    "\n",
    "> More info can be found [here](https://machinelearningmastery.com/visualize-deep-learning-neural-network-model-keras/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set this variable equal to your Keras model object.\n",
    "model_ = sequence_processer.model.model[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can either: create and save an image on our local machine,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model_, to_file='model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or, visulize it directly in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"337pt\" viewBox=\"0.00 0.00 328.47 337.00\" width=\"328pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 333)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-333 324.4727,-333 324.4727,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 5041402208 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>5041402208</title>\n",
       "<polygon fill=\"none\" points=\"96.0552,-292.5 96.0552,-328.5 224.4175,-328.5 224.4175,-292.5 96.0552,-292.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"160.2363\" y=\"-306.3\">input_1: InputLayer</text>\n",
       "</g>\n",
       "<!-- 4587412840 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>4587412840</title>\n",
       "<polygon fill=\"none\" points=\"78.1655,-219.5 78.1655,-255.5 242.3071,-255.5 242.3071,-219.5 78.1655,-219.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"160.2363\" y=\"-233.3\">embedding_1: Embedding</text>\n",
       "</g>\n",
       "<!-- 5041402208&#45;&gt;4587412840 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>5041402208-&gt;4587412840</title>\n",
       "<path d=\"M160.2363,-292.4551C160.2363,-284.3828 160.2363,-274.6764 160.2363,-265.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"163.7364,-265.5903 160.2363,-255.5904 156.7364,-265.5904 163.7364,-265.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5041305864 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>5041305864</title>\n",
       "<polygon fill=\"none\" points=\"22.5688,-146.5 22.5688,-182.5 297.9038,-182.5 297.9038,-146.5 22.5688,-146.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"160.2363\" y=\"-160.3\">bidirectional_1(lstm_1): Bidirectional(LSTM)</text>\n",
       "</g>\n",
       "<!-- 4587412840&#45;&gt;5041305864 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>4587412840-&gt;5041305864</title>\n",
       "<path d=\"M160.2363,-219.4551C160.2363,-211.3828 160.2363,-201.6764 160.2363,-192.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"163.7364,-192.5903 160.2363,-182.5904 156.7364,-192.5904 163.7364,-192.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5041402152 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>5041402152</title>\n",
       "<polygon fill=\"none\" points=\"0,-73.5 0,-109.5 320.4727,-109.5 320.4727,-73.5 0,-73.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"160.2363\" y=\"-87.3\">time_distributed_1(dense_1): TimeDistributed(Dense)</text>\n",
       "</g>\n",
       "<!-- 5041305864&#45;&gt;5041402152 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>5041305864-&gt;5041402152</title>\n",
       "<path d=\"M160.2363,-146.4551C160.2363,-138.3828 160.2363,-128.6764 160.2363,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"163.7364,-119.5903 160.2363,-109.5904 156.7364,-119.5904 163.7364,-119.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5041402768 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>5041402768</title>\n",
       "<polygon fill=\"none\" points=\"120.5415,-.5 120.5415,-36.5 199.9312,-36.5 199.9312,-.5 120.5415,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"160.2363\" y=\"-14.3\">crf_1: CRF</text>\n",
       "</g>\n",
       "<!-- 5041402152&#45;&gt;5041402768 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>5041402152-&gt;5041402768</title>\n",
       "<path d=\"M160.2363,-73.4551C160.2363,-65.3828 160.2363,-55.6764 160.2363,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"163.7364,-46.5903 160.2363,-36.5904 156.7364,-46.5904 163.7364,-46.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model_).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
